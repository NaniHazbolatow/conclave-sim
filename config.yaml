# Conclave Simulation Configuration

# LLM Backend Configuration
llm:
  # Backend type: "local" (HuggingFace) or "remote" (OpenRouter)
  backend: "remote"  # Options: "local", "remote"
  temperature: 0.7
  max_tokens: 500
  
  # Local HuggingFace Configuration
  local:
    model_name: "Qwen/Qwen2.5-3B-Instruct"
    # Alternative models (for easy switching)
    # model_name: "rednote-hilab/dots.llm1.inst"  # Requires custom implementation
    # model_name: "Qwen/Qwen2.5-1.5B-Instruct"
    # model_name: "microsoft/phi-3-mini-4k-instruct"  # May have cache issues
    # model_name: "meta-llama/Llama-3.2-1B-Instruct"
    
    # Device configuration
    device: "auto"  # Options: "auto", "cpu", "cuda", "mps"
    
    # Use quantization to reduce memory usage (requires bitsandbytes)
    use_quantization: false  # Set to true if bitsandbytes is available
    
    # Cache directory for downloaded models
    cache_dir: "~/.cache/huggingface"
    
    # Generation parameters
    do_sample: true
    top_p: 0.9
    repetition_penalty: 1.1
    
  # Remote OpenRouter Configuration  
  remote:
    # OpenRouter model name
    model_name: "openai/gpt-4o-mini"
    #model_name: "mistralai/mistral-nemo"
    #model_name: "qwen/qwen3-14b"

    # API configuration
    base_url: "https://openrouter.ai/api/v1"
    api_key_env: "OPENROUTER_API_KEY"  # Environment variable name
    
    # Generation parameters
    top_p: 0.9
    frequency_penalty: 0.1
    presence_penalty: 0.1

# Simulation Configuration
simulation:
  # Logging level
  log_level: "INFO"  # Options: "DEBUG", "INFO", "WARNING", "ERROR"
  
  # Number of discussion rounds
  max_discussion_rounds: 3
  
  # Maximum speaking agents per round
  max_speakers_per_round: 5
  
  # Enable detailed performance logging
  performance_logging: true

# Agent Configuration
agents:
  # Default agent behavior parameters
  default_urgency: 50  # 1-100 scale
  
  # Voting behavior
  voting:
    enable_abstention: false
    require_reasoning: true
    
  # Discussion behavior  
  discussion:
    min_message_length: 100
    max_message_length: 500
    enable_interruptions: false
